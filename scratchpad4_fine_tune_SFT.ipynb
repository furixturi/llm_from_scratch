{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad 4 - Instruction Fine-tuning (SFT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why instruction fine-tuning? A pretrained LLM is only good at text completion (predicting the next token), not good at following instructions. With instruction fine-tuning, we teach LLM to better follow instructions (generating texts that are desirable responses to the user's instructions). This is often called \"supervised fine-tuning (SFT)\".\n",
    "\n",
    "For SFT, we need to\n",
    "1. prepare instruction fine-tuning data that has desired input output pairs\n",
    "2. load and fine-tune a pretrained LLM\n",
    "3. evaluate the fine-tuned LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare data for supervised instruction fine-tuning, we need to:\n",
    "1. Get the raw dataset and format it according to the SFT template\n",
    "2. Create an SFT DataSet that formats json data into prompt template and tokenizes the texts into token IDs \n",
    "3. Create the DataLoader for the custom SFT DataSet which uses a custom collate function to prepare input and target batches of the encoded data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 SFT Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Train and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data is stored in a JSON file in `./data/sft/train`. Each sample JSON data has three fields:  `instruction`, `input` , and `output`.\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"instruction\": \"Evaluate the following phrase by transforming it into the spelling given.\",\n",
    "        \"input\": \"freind --> friend\",\n",
    "        \"output\": \"The spelling of the given phrase \\\"freind\\\" is incorrect, the correct spelling is \\\"friend\\\".\"\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "The test data for evaluation later will add the fine-tuned model's response for comparison. The file will be prepared in `./data/sft/test` and each data record will have an additional `response` field, e.g.:\n",
    "\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"instruction\": \"Rewrite the sentence using a simile.\",\n",
    "        \"input\": \"The car is very fast.\",\n",
    "        \"output\": \"The car is as fast as lightning.\",\n",
    "        \"model_response\": \"The car is as fast as a bullet.\"\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 LLM prompt templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we prepare the train data into inputs to the LLM. \n",
    "\n",
    "There are two example prompt template formats:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alpaca\n",
    "which Stanford CRFM used to train [Stanford Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html)\n",
    "  - They released 52K instruction-following data and the generation script in their [repo](https://github.com/tatsu-lab/stanford_alpaca#data-release). Our training data JSON is in exactly the same JSON format.\n",
    "  - The LLM prompt template reflects this format:\n",
    "\n",
    "With the input field:\n",
    "\n",
    "```\n",
    "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Input:\n",
    "{input}\n",
    "\n",
    "### Response:\n",
    "```\n",
    "Without the input field:\n",
    "```\n",
    "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{instruction}\n",
    "\n",
    "### Response:\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Phi-3\n",
    "\n",
    "which Microsoft Research used to train [Phi-3](https://github.com/microsoft/Phi-3CookBook/tree/main). \n",
    "\n",
    "The Phi-3 training data prompt template is as follows:\n",
    "\n",
    "```\n",
    "<|system|>\n",
    "Your Role<|end|>\n",
    "<|user|>\n",
    "Your Question?<|end|>\n",
    "<|assistant|>\n",
    "```\n",
    "\n",
    "A `jsonl` data would be like follows:\n",
    "\n",
    "```json\n",
    "{\"text\": \"<|user|>\\nWhen were iron maidens commonly used? <|end|>\\n<|assistant|> \\nIron maidens were never commonly used <|end|>\"}\n",
    "```\n",
    "\n",
    "But when using Azure AI to fine-tune, the data format is aligned with GPT, i.e.:\n",
    "\n",
    "```json\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"You are an Xbox customer support agent whose primary goal is to help users with issues they are experiencing with their Xbox devices. You are friendly and concise. You only provide factual answers to queries, and do not provide answers that are not related to Xbox.\"}, {\"role\": \"user\", \"content\": \"Is Xbox better than PlayStation?\"}, {\"role\": \"assistant\", \"content\": \"I apologize, but I cannot provide personal opinions. My primary job is to assist you with any issues related to your Xbox device. Do you have any Xbox-related issues that need addressing?\"}]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the Alpaca prompt template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3 Load and format data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training data\n",
    "\n",
    "import json\n",
    "data_file = './data/sft/train/instruction-data.json'\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data JSON lines: 1100\n",
      "Example:\n",
      "{\n",
      "    \"instruction\": \"Evaluate the following phrase by transforming it into the spelling given.\",\n",
      "    \"input\": \"freind --> friend\",\n",
      "    \"output\": \"The spelling of the given phrase \\\"freind\\\" is incorrect, the correct spelling is \\\"friend\\\".\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "f\"\"\"number of training data JSON lines: {len(data)}\n",
    "Example:\\n{json.dumps(data[0], indent=4)}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format it according to prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the data into prompt template for input to LLM\n",
    "\n",
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task.\"\n",
    "        f\"Write a response that appropriately completes the task.\"\n",
    "        f\"\\n\\n### Instruction\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input_text = f\"\\n\\n### Input\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task.Write a response that appropriately completes the task.\n",
      "\n",
      "### Instruction\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "model_input = format_input(data[0])\n",
    "desired_output = f\"\\n\\n### Response:\\n{data[0]['output']}\"\n",
    "\n",
    "print(model_input + desired_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.4 Split training, validation and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_portion = int(len(data) * 0.85) # 85% of the data for training\n",
    "test_portion = int(len(data) * 0.1) # 10% of the data for testing\n",
    "val_portion = len(data) - train_portion - test_portion # 5% of the data for validation\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 935, test: 110, val: 55\n"
     ]
    }
   ],
   "source": [
    "print(f\"train: {len(train_data)}, test: {len(test_data)}, val: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create custom DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a custom DataSet that at initialization: \n",
    "- format json data into LLM prompt template\n",
    "- tokenize the text into token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "\n",
    "        for entry in data:\n",
    "            # format the data input and response into prompt template\n",
    "            instruction_plus_input = (\n",
    "                f\"Below is an instruction that describes a task.\"\n",
    "                f\"Write a response that appropriately completes the task.\"\n",
    "                f\"\\n\\n### Instruction\\n{entry['instruction']}\"\n",
    "            ) + (f\"\\n\\n### Input\\n{entry['input']}\" if entry[\"input\"] else \"\")\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "\n",
    "            # tokenize the full text\n",
    "            self.encoded_texts.append(\n",
    "                tokenizer.encode(full_text)\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.encoded_texts[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## training data json ########\n",
      "training json data length: 935\n",
      "first training data json: {\n",
      "    \"instruction\": \"Evaluate the following phrase by transforming it into the spelling given.\",\n",
      "    \"input\": \"freind --> friend\",\n",
      "    \"output\": \"The spelling of the given phrase \\\"freind\\\" is incorrect, the correct spelling is \\\"friend\\\".\"\n",
      "}\n",
      "\n",
      "######## training dataset ########\n",
      "training dataset size: 935\n",
      "first item of the training dataset: \n",
      "[21106, 318, 281, 12064, 326, 8477, 257, 4876, 13, 16594, 257, 2882, 326, 20431, 32543, 262, 4876, 13, 198, 198, 21017, 46486, 198, 36, 2100, 4985, 262, 1708, 9546, 416, 25449, 340, 656, 262, 24993, 1813, 13, 198, 198, 21017, 23412, 198, 19503, 521, 14610, 1545, 198, 198, 21017, 18261, 25, 198, 464, 24993, 286, 262, 1813, 9546, 366, 19503, 521, 1, 318, 11491, 11, 262, 3376, 24993, 318, 366, 6726, 1911]\n",
      "Decoded first item of the training dataset: \n",
      "Below is an instruction that describes a task.Write a response that appropriately completes the task.\n",
      "\n",
      "### Instruction\n",
      "Evaluate the following phrase by transforming it into the spelling given.\n",
      "\n",
      "### Input\n",
      "freind --> friend\n",
      "\n",
      "### Response:\n",
      "The spelling of the given phrase \"freind\" is incorrect, the correct spelling is \"friend\".\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "\n",
    "print(\"######## training data json ########\")\n",
    "print(f\"training json data length: {len(train_dataset)}\")\n",
    "print(f\"first training data json: {json.dumps(train_data[0], indent=4)}\")\n",
    "print(\"\\n######## training dataset ########\")\n",
    "print(f\"training dataset size: {len(train_dataset)}\")\n",
    "print(f\"first item of the training dataset: \\n{train_dataset[0]}\")\n",
    "print(f\"Decoded first item of the training dataset: \\n{tokenizer.decode(train_dataset[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Create DataLoader with a custom colloate function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finetuning a pretrained LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fine-tune a pretrained LLM, we need to\n",
    "1. load the pretrained LLM\n",
    "2. train (fine-tune) it on SFT data\n",
    "3. save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Evaluating the fine-tuned LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the fine-tuned LLM, we will use another LLM.\n",
    "1. run inference on test set and save the responses\n",
    "2. compare ground truth in test set with generated responses\n",
    "3. use another LLM to score the fine-tuned responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
