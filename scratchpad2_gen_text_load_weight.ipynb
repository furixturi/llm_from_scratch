{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad 2 - Generate text, download pretrained model and load model weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple generate text function with greedy sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In greedy decoding, the model always chooses the token with the highest probability (the biggest logit) to be the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_tokens_simple(model, input_idx, max_new_tokens, context_size):\n",
    "    # input_idx shape: (batch_size, n_tokens) in the current context\n",
    "\n",
    "    # we will output the input tokens plus the generarted new tokens\n",
    "    output_idx = input_idx\n",
    "    # iterate over the number of new tokens to generate\n",
    "    for _ in range(max_new_tokens):\n",
    "        # in case the current tokens are longer than the model's supported context_size, \n",
    "        # crop the tokens in the front and preserve tokens that fit in the model's `context_size`\n",
    "        idx = output_idx[:, -context_size:]\n",
    "\n",
    "        # get the model's prediction for the current context\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx)\n",
    "\n",
    "        # predicted next token is at the last position of the logits, so we extract only the last token's logits.\n",
    "        ## logits shape: (batch_size, context_size, vocab_size) -> next_token_logits shape: (batch_size, vocab_size)\n",
    "        next_token_logits = logits[:, -1, :]\n",
    "        # to find the index of the token with the highest probability, we only need to find the index of the largest logit in the last dimension (vocab_size)\n",
    "        ## keepdim=True ensures that the output has the same shape as the input, except in the dimension where we take the argmax\n",
    "        next_token_idx = torch.argmax(next_token_logits, dim=-1, keepdim=True) # shape: (batch_size, 1)\n",
    "        # concatenate the new token to the output\n",
    "        output_idx = torch.cat((output_idx, next_token_idx), dim=1)\n",
    "\n",
    "    return output_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test generate_tokens_simple function on our untrained GPT-2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (dropout_emb): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import tiktoken\n",
    "from gpt.gpt_model import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"embedding_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"dropout_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()    # disable dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_context = \"Hi, I am a large language model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "encoded = tokenizer.encode(start_context)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "                      IN\n",
      "==================================================\n",
      "Input text: Hi, I am a large language model\n",
      "Encoded input text: [17250, 11, 314, 716, 257, 1588, 3303, 2746]\n",
      "Encoded tensor shape: torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{50*'='}\\n{22*' '}IN\\n{50*'='}\")\n",
    "print(f\"Input text: {start_context}\")\n",
    "print(f\"Encoded input text: {encoded}\")  # encoded token IDs\n",
    "print(f\"Encoded tensor shape: {encoded_tensor.shape}\")  # shape: (batch_size, n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = generate_tokensns_simple(\n",
    "    model=model,\n",
    "    input_idx=encoded_tensor,\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated text is going to be gibberish as the model is only initialized with random weights, not even pretrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "                      OUT\n",
      "==================================================\n",
      "Output tensor: tensor([[17250,    11,   314,   716,   257,  1588,  3303,  2746, 45199, 41518,\n",
      "         45173, 31263, 23195,  8603,  7384, 10261, 18815, 30220]])\n",
      "Output text: Hi, I am a large language model fixme Satanic cordsulkan275 equally attacked 93 colony corrobor\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{50*'='}\\n{22*' '}OUT\\n{50*'='}\")\n",
    "print(f\"Output tensor: {out}\")\n",
    "print(f\"Output text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download OpenAI's pretrained GPT-2 weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download utility function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! The following code uses urllib.request but results in and error in MacOS\n",
    "```\n",
    "URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1000)>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function to download a file\n",
    "import os\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file\n",
    "\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            # Get the total file size from headers, defaulting to 0 if not present\n",
    "            file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "            # Check if file exists and has the same size\n",
    "            if os.path.exists(destination):\n",
    "                file_size_local = os.path.getsize(destination)\n",
    "                if file_size == file_size_local:\n",
    "                    print(f\"File already exists and is up-to-date: {destination}\")\n",
    "                    return\n",
    "\n",
    "            # Define the block size for reading the file\n",
    "            block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "            # Initialize the progress bar with total file size\n",
    "            progress_bar_description = os.path.basename(url)  # Extract filename from URL\n",
    "            with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "                # Open the destination file in binary write mode\n",
    "                with open(destination, \"wb\") as file:\n",
    "                    # Read the file in chunks and write to destination\n",
    "                    while True:\n",
    "                        chunk = response.read(block_size)\n",
    "                        if not chunk:\n",
    "                            break\n",
    "                        file.write(chunk)\n",
    "                        progress_bar.update(len(chunk))  # Update progress bar\n",
    "    except urllib.error.HTTPError:\n",
    "        s = (\n",
    "            f\"The specified URL ({url}) is incorrect, the internet connection cannot be established,\"\n",
    "            \"\\nor the requested file is temporarily unavailable.\\nPlease visit the following website\"\n",
    "            \" for help: https://github.com/rasbt/LLMs-from-scratch/discussions/273\")\n",
    "        print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative download util function using `requests` package instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(url, destination):\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download OpenAI's GPT-2 pretrained model to a local folder `./models/{model_size}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_gpt2_model(model_size, models_dir):\n",
    "    # Validate model size\n",
    "    allowed_sizes = (\"124M\", \"355M\", \"774M\", \"1558M\")\n",
    "    if model_size not in allowed_sizes:\n",
    "        raise ValueError(f\"Model size not in {allowed_sizes}\")\n",
    "\n",
    "    # Define paths\n",
    "    model_dir = os.path.join(models_dir, model_size)\n",
    "    base_url = \"https://openaipublic.blob.core.windows.net/gpt-2/models\"\n",
    "    filenames = [\n",
    "        \"checkpoint\", \"encoder.json\", \"hparams.json\",\n",
    "        \"model.ckpt.data-00000-of-00001\", \"model.ckpt.index\",\n",
    "        \"model.ckpt.meta\", \"vocab.bpe\"\n",
    "    ]\n",
    "\n",
    "    # Download files\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    for filename in filenames:\n",
    "        file_url = os.path.join(base_url, model_size, filename)\n",
    "        file_path = os.path.join(model_dir, filename)\n",
    "        download_file(file_url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the smallest GPT-2(124M) will take 488M disk space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 51.2kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 662kiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 55.0kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [07:04<00:00, 1.17MiB/s]  \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 3.05MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 679kiB/s] \n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 656kiB/s] \n"
     ]
    }
   ],
   "source": [
    "download_gpt2_model(\"124M\", \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load OpenAI's GPT-2 pretrianed weights to our GPTModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Extract settings and parameters from downloaded model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load settings and params of downloaded model. (We have to use Tensorflow as OpenAI's GPT-2 was trained with TensorFlow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/124M/model.ckpt\n",
      "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "\n",
    "model_dir = os.path.join(\"models\", \"124M\")\n",
    "\n",
    "# finds the latest checkpoint file in the model directory\n",
    "tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "print(tf_ckpt_path)\n",
    "\n",
    "settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "print(settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's list each layer's keys and shapes in the checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model/h0/attn/c_attn/b', [2304]),\n",
       " ('model/h0/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h0/attn/c_proj/b', [768]),\n",
       " ('model/h0/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h0/ln_1/b', [768]),\n",
       " ('model/h0/ln_1/g', [768]),\n",
       " ('model/h0/ln_2/b', [768]),\n",
       " ('model/h0/ln_2/g', [768]),\n",
       " ('model/h0/mlp/c_fc/b', [3072]),\n",
       " ('model/h0/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h0/mlp/c_proj/b', [768]),\n",
       " ('model/h0/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h1/attn/c_attn/b', [2304]),\n",
       " ('model/h1/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h1/attn/c_proj/b', [768]),\n",
       " ('model/h1/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h1/ln_1/b', [768]),\n",
       " ('model/h1/ln_1/g', [768]),\n",
       " ('model/h1/ln_2/b', [768]),\n",
       " ('model/h1/ln_2/g', [768]),\n",
       " ('model/h1/mlp/c_fc/b', [3072]),\n",
       " ('model/h1/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h1/mlp/c_proj/b', [768]),\n",
       " ('model/h1/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h10/attn/c_attn/b', [2304]),\n",
       " ('model/h10/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h10/attn/c_proj/b', [768]),\n",
       " ('model/h10/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h10/ln_1/b', [768]),\n",
       " ('model/h10/ln_1/g', [768]),\n",
       " ('model/h10/ln_2/b', [768]),\n",
       " ('model/h10/ln_2/g', [768]),\n",
       " ('model/h10/mlp/c_fc/b', [3072]),\n",
       " ('model/h10/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h10/mlp/c_proj/b', [768]),\n",
       " ('model/h10/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h11/attn/c_attn/b', [2304]),\n",
       " ('model/h11/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h11/attn/c_proj/b', [768]),\n",
       " ('model/h11/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h11/ln_1/b', [768]),\n",
       " ('model/h11/ln_1/g', [768]),\n",
       " ('model/h11/ln_2/b', [768]),\n",
       " ('model/h11/ln_2/g', [768]),\n",
       " ('model/h11/mlp/c_fc/b', [3072]),\n",
       " ('model/h11/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h11/mlp/c_proj/b', [768]),\n",
       " ('model/h11/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h2/attn/c_attn/b', [2304]),\n",
       " ('model/h2/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h2/attn/c_proj/b', [768]),\n",
       " ('model/h2/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h2/ln_1/b', [768]),\n",
       " ('model/h2/ln_1/g', [768]),\n",
       " ('model/h2/ln_2/b', [768]),\n",
       " ('model/h2/ln_2/g', [768]),\n",
       " ('model/h2/mlp/c_fc/b', [3072]),\n",
       " ('model/h2/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h2/mlp/c_proj/b', [768]),\n",
       " ('model/h2/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h3/attn/c_attn/b', [2304]),\n",
       " ('model/h3/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h3/attn/c_proj/b', [768]),\n",
       " ('model/h3/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h3/ln_1/b', [768]),\n",
       " ('model/h3/ln_1/g', [768]),\n",
       " ('model/h3/ln_2/b', [768]),\n",
       " ('model/h3/ln_2/g', [768]),\n",
       " ('model/h3/mlp/c_fc/b', [3072]),\n",
       " ('model/h3/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h3/mlp/c_proj/b', [768]),\n",
       " ('model/h3/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h4/attn/c_attn/b', [2304]),\n",
       " ('model/h4/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h4/attn/c_proj/b', [768]),\n",
       " ('model/h4/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h4/ln_1/b', [768]),\n",
       " ('model/h4/ln_1/g', [768]),\n",
       " ('model/h4/ln_2/b', [768]),\n",
       " ('model/h4/ln_2/g', [768]),\n",
       " ('model/h4/mlp/c_fc/b', [3072]),\n",
       " ('model/h4/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h4/mlp/c_proj/b', [768]),\n",
       " ('model/h4/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h5/attn/c_attn/b', [2304]),\n",
       " ('model/h5/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h5/attn/c_proj/b', [768]),\n",
       " ('model/h5/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h5/ln_1/b', [768]),\n",
       " ('model/h5/ln_1/g', [768]),\n",
       " ('model/h5/ln_2/b', [768]),\n",
       " ('model/h5/ln_2/g', [768]),\n",
       " ('model/h5/mlp/c_fc/b', [3072]),\n",
       " ('model/h5/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h5/mlp/c_proj/b', [768]),\n",
       " ('model/h5/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h6/attn/c_attn/b', [2304]),\n",
       " ('model/h6/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h6/attn/c_proj/b', [768]),\n",
       " ('model/h6/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h6/ln_1/b', [768]),\n",
       " ('model/h6/ln_1/g', [768]),\n",
       " ('model/h6/ln_2/b', [768]),\n",
       " ('model/h6/ln_2/g', [768]),\n",
       " ('model/h6/mlp/c_fc/b', [3072]),\n",
       " ('model/h6/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h6/mlp/c_proj/b', [768]),\n",
       " ('model/h6/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h7/attn/c_attn/b', [2304]),\n",
       " ('model/h7/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h7/attn/c_proj/b', [768]),\n",
       " ('model/h7/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h7/ln_1/b', [768]),\n",
       " ('model/h7/ln_1/g', [768]),\n",
       " ('model/h7/ln_2/b', [768]),\n",
       " ('model/h7/ln_2/g', [768]),\n",
       " ('model/h7/mlp/c_fc/b', [3072]),\n",
       " ('model/h7/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h7/mlp/c_proj/b', [768]),\n",
       " ('model/h7/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h8/attn/c_attn/b', [2304]),\n",
       " ('model/h8/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h8/attn/c_proj/b', [768]),\n",
       " ('model/h8/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h8/ln_1/b', [768]),\n",
       " ('model/h8/ln_1/g', [768]),\n",
       " ('model/h8/ln_2/b', [768]),\n",
       " ('model/h8/ln_2/g', [768]),\n",
       " ('model/h8/mlp/c_fc/b', [3072]),\n",
       " ('model/h8/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h8/mlp/c_proj/b', [768]),\n",
       " ('model/h8/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/h9/attn/c_attn/b', [2304]),\n",
       " ('model/h9/attn/c_attn/w', [1, 768, 2304]),\n",
       " ('model/h9/attn/c_proj/b', [768]),\n",
       " ('model/h9/attn/c_proj/w', [1, 768, 768]),\n",
       " ('model/h9/ln_1/b', [768]),\n",
       " ('model/h9/ln_1/g', [768]),\n",
       " ('model/h9/ln_2/b', [768]),\n",
       " ('model/h9/ln_2/g', [768]),\n",
       " ('model/h9/mlp/c_fc/b', [3072]),\n",
       " ('model/h9/mlp/c_fc/w', [1, 768, 3072]),\n",
       " ('model/h9/mlp/c_proj/b', [768]),\n",
       " ('model/h9/mlp/c_proj/w', [1, 3072, 768]),\n",
       " ('model/ln_f/b', [768]),\n",
       " ('model/ln_f/g', [768]),\n",
       " ('model/wpe', [1024, 768]),\n",
       " ('model/wte', [50257, 768])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.list_variables(tf_ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to extract settings and parameters from downloaded model, carefully mapping each layer's parameters' keys and weight dictionariies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "def load_model_settings_and_params(model_dir):\n",
    "    # finds the latest checkpoint file in the model directory\n",
    "    tf_ckpt_path = tf.train.latest_checkpoint(model_dir)\n",
    "    # load the model settings from the hparams.json file\n",
    "    settings = json.load(open(os.path.join(model_dir, \"hparams.json\")))\n",
    "\n",
    "    # load the model parameters from the checkpoint file, layer by layer\n",
    "    params = {\"blocks\": [{} for _ in range(settings[\"n_layer\"])]}\n",
    "    for name, _ in tf.train.list_variables(tf_ckpt_path):\n",
    "        # load the variable of the layer and remove singleton dimensions\n",
    "        variable_array = np.squeeze(tf.train.load_variable(tf_ckpt_path, name))\n",
    "        # print(name, variable_array)   # uncomment to see the variable names and arrays\n",
    "\n",
    "        # process the variable name (e.g. \"model/wte\", \"model/ln_f/g\", \"model/h2/mlp/c_proj/w\") to extract relevant parts\n",
    "        variable_name_parts = name.split(\"/\")[1:]  # skip the \"model/\" prefix\n",
    "\n",
    "        # for the n layers, identify the target dictionary for the variable\n",
    "        target_dict = params\n",
    "        if variable_name_parts[0].startswith(\"h\"):\n",
    "            layer_number = int(variable_name_parts[0][1:])\n",
    "            target_dict = params[\"blocks\"][layer_number]\n",
    "        \n",
    "        # recursively access or create nested dictionaries\n",
    "        for key in variable_name_parts[1:-1]:\n",
    "            target_dict = target_dict.setdefault(key, {})\n",
    "        \n",
    "        # assign the variable array to the last key\n",
    "        last_key = variable_name_parts[-1]\n",
    "        target_dict[last_key] = variable_array\n",
    "\n",
    "    return settings, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = os.path.join(\"models\", \"124M\")\n",
    "\n",
    "settings, params = load_model_settings_and_params(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks\n",
      "    List item 0:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 1:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 2:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 3:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 4:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 5:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 6:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 7:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 8:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 9:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 10:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    List item 11:\n",
      "    attn\n",
      "        c_attn\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "    ln_1\n",
      "        b\n",
      "        g\n",
      "    ln_2\n",
      "        b\n",
      "        g\n",
      "    mlp\n",
      "        c_fc\n",
      "            b\n",
      "            w\n",
      "        c_proj\n",
      "            b\n",
      "            w\n",
      "b\n",
      "g\n",
      "wpe\n",
      "wte\n"
     ]
    }
   ],
   "source": [
    "def print_keys(d, indent=0):\n",
    "    \"\"\"Recursively prints all keys in a dictionary with indentation to show depth.\"\"\"\n",
    "    for key, value in d.items():\n",
    "        print(\" \" * indent + str(key))\n",
    "        if isinstance(value, dict):\n",
    "            print_keys(value, indent + 4)\n",
    "        elif isinstance(value, list):\n",
    "            # Iterate through list items to check for dictionaries\n",
    "            for index, item in enumerate(value):\n",
    "                if isinstance(item, dict):\n",
    "                    print(\" \" * (indent + 4) + f\"List item {index}:\")\n",
    "                    print_keys(item, indent + 4)  # Increase indent for items within lists\n",
    "\n",
    "print_keys(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load weights into a GPTModel instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Observe the parameter structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign weight utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shapes do not match: Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a new GPTModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (dropout_emb): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt.gpt_model import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"embedding_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"dropout_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-Key-Value bias\n",
    "}\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print all OpenAI parameter keys recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks\n",
      "    List item 0:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 1:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 2:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 3:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 4:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 5:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 6:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 7:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 8:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 9:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 10:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "    List item 11:\n",
      "        attn\n",
      "            c_attn\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "        ln_1\n",
      "            b\n",
      "            g\n",
      "        ln_2\n",
      "            b\n",
      "            g\n",
      "        mlp\n",
      "            c_fc\n",
      "                b\n",
      "                w\n",
      "            c_proj\n",
      "                b\n",
      "                w\n",
      "b\n",
      "g\n",
      "wpe\n",
      "wte\n"
     ]
    }
   ],
   "source": [
    "def print_keys(d, indent=0):\n",
    "    \"\"\"Recursively prints all keys in a dictionary with indentation to show depth.\"\"\"\n",
    "    for key, value in d.items():\n",
    "        print(\" \" * indent + str(key))\n",
    "        if isinstance(value, dict):\n",
    "            print_keys(value, indent + 4)\n",
    "        elif isinstance(value, list):\n",
    "            # Iterate through list items to check for dictionaries\n",
    "            for index, item in enumerate(value):\n",
    "                if isinstance(item, dict):\n",
    "                    print(\" \" * (indent + 4) + f\"List item {index}:\")\n",
    "                    print_keys(item, indent + 8)  # Increase indent for items within lists\n",
    "\n",
    "print_keys(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wpe\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our GPTModel's architecture for reference:\n",
    "```\n",
    "GPTModel(\n",
    "  (tok_emb): Embedding(50257, 768)\n",
    "  (pos_emb): Embedding(1024, 768)\n",
    "  (dropout_emb): Dropout(p=0.1, inplace=False)\n",
    "  (transformer_blocks): Sequential(\n",
    "    (0): TransformerBlock(\n",
    "      (norm1): LayerNorm()\n",
    "      (att): MultiHeadAttention(\n",
    "        (W_q): Linear(in_features=768, out_features=768, bias=False)\n",
    "        (W_k): Linear(in_features=768, out_features=768, bias=False)\n",
    "        (W_v): Linear(in_features=768, out_features=768, bias=False)\n",
    "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
    "        (dropout): Dropout(p=0.1, inplace=False)\n",
    "      )\n",
    "      (norm2): LayerNorm()\n",
    "      (ff): FeedForward(\n",
    "        (layers): Sequential(\n",
    "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
    "          (1): GELU()\n",
    "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
    "        )\n",
    "      )\n",
    "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
    "    )\n",
    "    ...\n",
    "  )\n",
    "  (final_norm): LayerNorm()\n",
    "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now here is the mapping between OpenAI GPT-2 weights and our GPTModel weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "blocks  -   transformer_blocks\n",
    "    List item 0:\n",
    "        attn    -   att\n",
    "            c_attn  -   concatenated W_q, W_k, W_v\n",
    "                b   -   concatenated bias of W_q, W_k, W_v\n",
    "                w   -   concatenated weight of W_q, W_k, W_v\n",
    "            c_proj  -   out_proj\n",
    "                b   -   outproj.bias\n",
    "                w   -   outproj.weight\n",
    "        ln_1   -   norm1\n",
    "            b   -   norm1.shift\n",
    "            g   -   norm1.scale\n",
    "        ln_2   -   norm2\n",
    "            b   -   norm2.shift\n",
    "            g   -   norm2.scale\n",
    "        mlp    -   ff\n",
    "            c_fc   -   ff.layers[0]\n",
    "                b   -   ff.layers[0].bias\n",
    "                w   -   ff.layers[0].weight\n",
    "            c_proj  -   ff.layers[2]\n",
    "                b   -   ff.layers[2].bias\n",
    "                w   -   ff.layers[2].weight\n",
    "    ... other 11 layers of transformer blocks\n",
    "b   -   final_norm.shift\n",
    "g   -   final_norm.scale\n",
    "wpe -   pos_emb\n",
    "wte -   tok_emb, out_head\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Functions to assign weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A utility function that instantiates a weight dictionary into a `torch.nn.Parameter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shapes do not match: Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    # token and position embeddings\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "\n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        # Masked Multi Head Attention weights\n",
    "        q_w, k_w, v_w = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.transformer_blocks[b].att.W_q.weight = assign(gpt.transformer_blocks[b].att.W_q.weight, q_w.T)        \n",
    "        gpt.transformer_blocks[b].att.W_k.weight = assign(gpt.transformer_blocks[b].att.W_k.weight, k_w.T)        \n",
    "        gpt.transformer_blocks[b].att.W_v.weight = assign(gpt.transformer_blocks[b].att.W_v.weight, v_w.T)\n",
    "        # Masked Multi Head Attention biases\n",
    "        q_b, k_b, v_b = np.split((params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.transformer_blocks[b].att.W_q.bias = assign(gpt.transformer_blocks[b].att.W_q.bias, q_b)        \n",
    "        gpt.transformer_blocks[b].att.W_k.bias = assign(gpt.transformer_blocks[b].att.W_k.bias, k_b)        \n",
    "        gpt.transformer_blocks[b].att.W_v.bias = assign(gpt.transformer_blocks[b].att.W_v.bias, v_b)\n",
    "        # Masked Multi Head Attention output projection weights and biases\n",
    "        gpt.transformer_blocks[b].att.out_proj.weight = assign(gpt.transformer_blocks[b].att.out_proj.weight, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)   \n",
    "        gpt.transformer_blocks[b].att.out_proj.bias = assign(gpt.transformer_blocks[b].att.out_proj.bias, params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # Feed Forward weights and biases\n",
    "        gpt.transformer_blocks[b].ff.layers[0].weight = assign(gpt.transformer_blocks[b].ff.layers[0].weight, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)   \n",
    "        gpt.transformer_blocks[b].ff.layers[0].bias = assign(gpt.transformer_blocks[b].ff.layers[0].bias, params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])   \n",
    "        gpt.transformer_blocks[b].ff.layers[2].weight = assign(gpt.transformer_blocks[b].ff.layers[2].weight, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)   \n",
    "        gpt.transformer_blocks[b].ff.layers[2].bias = assign(gpt.transformer_blocks[b].ff.layers[2].bias, params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        # 2 Layer Normalization weights and biases\n",
    "        gpt.transformer_blocks[b].norm1.scale = assign(gpt.transformer_blocks[b].norm1.scale, params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.transformer_blocks[b].norm1.shift = assign(gpt.transformer_blocks[b].norm1.shift, params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.transformer_blocks[b].norm2.scale = assign(gpt.transformer_blocks[b].norm2.scale, params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.transformer_blocks[b].norm2.shift = assign(gpt.transformer_blocks[b].norm2.shift, params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "    # Final layer norm\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "\n",
    "    # Output projection weights (reuses token embedding)\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a new GPTModel to load the OpenAI's GPT-2 weights.\n",
    "!!! OpenAI's GPT-2 uses qkv bias, so we need to update the config to set `qkv_bias` to be `True`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (dropout_emb): Dropout(p=0.1, inplace=False)\n",
       "  (transformer_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_k): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_v): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (norm2): LayerNorm()\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gpt.gpt_model import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"embedding_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"dropout_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": True,  # Query-Key-Value bias set to True!\n",
    "}\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights_into_gpt(model, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test the model again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same input as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "                      IN\n",
      "==================================================\n",
      "Input text: Hi, I am a large language model.\n",
      "Encoded input text: [17250, 11, 314, 716, 257, 1588, 3303, 2746, 13]\n",
      "Encoded tensor shape: torch.Size([1, 9])\n"
     ]
    }
   ],
   "source": [
    "start_context = \"Hi, I am a large language model.\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "encoded = tokenizer.encode(start_context)\n",
    "encoded_tensor = torch.tensor(encoded).unsqueeze(0)  # add batch dimension\n",
    "print(f\"\\n{50*'='}\\n{22*' '}IN\\n{50*'='}\")\n",
    "print(f\"Input text: {start_context}\")\n",
    "print(f\"Encoded input text: {encoded}\")  # encoded token IDs\n",
    "print(f\"Encoded tensor shape: {encoded_tensor.shape}\")  # shape: (batch_size, n_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see that the output is becoming coherent sentences now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "                      OUT\n",
      "==================================================\n",
      "Output tensor: tensor([[17250,    11,   314,   716,   257,  1588,  3303,  2746,    13,   314,\n",
      "           716,   257,  1263, 24292,    13,   314,   716,   257,  1263]])\n",
      "Output text: Hi, I am a large language model. I am a big programmer. I am a big\n"
     ]
    }
   ],
   "source": [
    "out = generate_tokensnsns_simple(\n",
    "    model=model,\n",
    "    input_idx=encoded_tensor,\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    ")\n",
    "decoded_text = tokenizer.decode(out.squeeze(0).tolist())\n",
    "\n",
    "print(f\"\\n{50*'='}\\n{22*' '}OUT\\n{50*'='}\")\n",
    "print(f\"Output tensor: {out}\")\n",
    "print(f\"Output text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better `generate` function that have `temperature` and `top_k` settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float('-inf')).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "                      OUT\n",
      "==================================================\n",
      "Output tensor: tensor([[17250,    11,   314,   716,   257,  1588,  3303,  2746,    13,   314,\n",
      "           716,   257,  1263, 24292,    13,   314,   716,   257,  1263]])\n",
      "Output text: Hi, I am a large language model. I do not know that I am the real one behind our projects, or that we are not the real creators.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out2 = generate(\n",
    "    model=model,\n",
    "    idx=encoded_tensor,\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    temperature=1.0,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "decoded_text = tokenizer.decode(out2.squeeze(0).tolist())\n",
    "\n",
    "print(f\"\\n{50*'='}\\n{22*' '}OUT\\n{50*'='}\")\n",
    "print(f\"Output tensor: {out}\")\n",
    "print(f\"Output text: {decoded_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
