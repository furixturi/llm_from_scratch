{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad 3 - Pre-train LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate text generation loss: cross-entropy and perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Cross-entropy loss (average negative log probability value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model generates logits tensor of (batch_size, seq_length, vocab_size), the last dimension can be interpreted as the mode's predicted probability of each token in the whole vacabulary of being the next token. Applying `softmax` makes them probability values from 0 to 1, sumning up to 1.\n",
    "\n",
    "For the target tokens (the input tokens minus the first token and plus the real next token in the training data), we want to maximize their logits in the output tokens. Which means we want to\n",
    "-  **maximize the target tokens' softmax-ed values in the ouput tensor to 1**. \n",
    "\n",
    "It's easier to do this if we first calculate their log values, because to max the probabilities to 1, then we just need to maximize their log values (which are negative numbers) to 0. \n",
    "\n",
    "In ML we need to define a loss function and minimize one loss value calculated from the function. So instead of maximizing muliple log values of all the batches' ouput token sequences, we define the loss to be the \n",
    "- **averaged negative log probability value** of all target tokens in the output tensor, from all batches in the output concatenated. \n",
    "\n",
    "This is our **cross-entropy** loss. PyTorch provides a `cross_entropy` function which combines two operations:\n",
    "- apply softmax \n",
    "- calculate log of softmax\n",
    "- calculate negative log-likelihood loss\n",
    "- average loss across batches\n",
    "\n",
    "To use it, we need to flatten the logits tensor and the target token IDs batch tensor (aka concat all batches):\n",
    "\n",
    "```\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, target_idx_batch_flat)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt.gpt_model import GPTModel\n",
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"embedding_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"dropout_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval(); # ; is used to suppress the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full text tokens: [464, 2068, 7586, 21831, 18045, 625, 262, 16931, 3290]\n"
     ]
    }
   ],
   "source": [
    "full_text = \"The quick brown fox jumps over the lazy dog\"\n",
    "full_text_tokens = tokenizer.encode(full_text)\n",
    "print(f\"Full text tokens: {full_text_tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: The quick brown fox\n",
      "Input idx batch tensor: tensor([[  464,  2068,  7586, 21831]])\n"
     ]
    }
   ],
   "source": [
    "input_idx = full_text_tokens[:4]\n",
    "input_text = tokenizer.decode(input_idx)\n",
    "print(f\"Input text: {input_text}\")\n",
    "input_idx_batch = torch.tensor(input_idx).unsqueeze(0)\n",
    "print(f\"Input idx batch tensor: {input_idx_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output logits shape: torch.Size([1, 4, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(input_idx_batch)\n",
    "print(f\"Output logits shape: {logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target text:  quick brown fox jumps\n",
      "Target idx batch tensor: tensor([[ 2068,  7586, 21831, 18045]])\n"
     ]
    }
   ],
   "source": [
    "target_idx = full_text_tokens[1:5]\n",
    "target_text = tokenizer.decode(target_idx)\n",
    "print(f\"Target text: {target_text}\")\n",
    "target_idx_batch = torch.tensor(target_idx).unsqueeze(0)\n",
    "print(f\"Target idx batch tensor: {target_idx_batch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7479)\n"
     ]
    }
   ],
   "source": [
    "# logits is the model's output of shape (batch_size, seq_len, vocab_size) -> (batch_size * seq_len, vocab_size)\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "# targets is the target sequence's token IDs shape (batch_size, seq_len) -> (batch_size * seq_len)\n",
    "targets_idx_flat = target_idx_batch.flatten(0, 1)\n",
    "# Compute the cross entropy loss\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_idx_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our randomly initialized GPT2 model, the cross-entropy loss is 10.7479."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perplexity** is also a metric that measures how well the model predicts a sequence of tokens. It is the **exponential of the average negaltive log-likelihood** of the predicted probabilities for each token in a sequence, aka\n",
    "- the **exponential of cross-entropy**\n",
    "  \n",
    "It tells us how \"surprised\" the model is by the test data. It can be interpreted as how many choices the model thinks it has when predicting the next token.\n",
    "\n",
    "$$\\text{Perplexity} = \\exp\\left(-\\frac{1}{N} \\sum_{i=1}^{N} \\log P(x_i)\\right)$$\n",
    "\n",
    "```\n",
    "cros_entropy_loss = torch.nn.functional.cross_entropy(logits_flat, target_idx_batch_flat)\n",
    "perplexity_loss = torch.exp(cros_entropy_loss)\n",
    "```\n",
    "\n",
    "- A perplexity of 1 means the model is extremely sure (assigns probability of 1 to the correct next token ID).\n",
    "- A high perplexity means the model is uncertain about the next token.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(46531.8984)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our untrained model has perplexity of 46532, with the vocabulary size 50257, it is basically random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training data pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Create dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a small dataset first. Download the \"verdict.txt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# download file from url to destination, showing progress bar\n",
    "def download_file(url, destination):\n",
    "    # Create the destination directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "    # Send a GET request to download the file in streaming mode\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Get the total file size from headers, defaulting to 0 if not present\n",
    "    file_size = int(response.headers.get(\"content-length\", 0))\n",
    "\n",
    "    # Check if file exists and has the same size\n",
    "    if os.path.exists(destination):\n",
    "        file_size_local = os.path.getsize(destination)\n",
    "        if file_size == file_size_local:\n",
    "            print(f\"File already exists and is up-to-date: {destination}\")\n",
    "            return\n",
    "\n",
    "    # Define the block size for reading the file\n",
    "    block_size = 1024  # 1 Kilobyte\n",
    "\n",
    "    # Initialize the progress bar with total file size\n",
    "    progress_bar_description = url.split(\"/\")[-1]  # Extract filename from URL\n",
    "    with tqdm(\n",
    "        total=file_size, unit=\"iB\", unit_scale=True, desc=progress_bar_description\n",
    "    ) as progress_bar:\n",
    "        # Open the destination file in binary write mode\n",
    "        with open(destination, \"wb\") as file:\n",
    "            # Iterate over the file data in chunks\n",
    "            for chunk in response.iter_content(block_size):\n",
    "                progress_bar.update(len(chunk))  # Update progress bar\n",
    "                file.write(chunk)  # Write the chunk to the file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the-verdict.txt: 20.5kiB [00:00, 15.5MiB/s]                  \n"
     ]
    }
   ],
   "source": [
    "data_folder = \"data\"\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "destination = os.path.join(data_folder, file_path)\n",
    "download_file(url, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n",
      " rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would h\n",
      "it for me! The Strouds stand alone, and happen once--but there's no exterminating our kind of art.\"\n"
     ]
    }
   ],
   "source": [
    "with open(destination, 'r', encoding='utf-8') as file:\n",
    "    text_data = file.read()\n",
    "print(text_data[:99])\n",
    "print(text_data[200:299])\n",
    "print(text_data[-99:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 20479\n",
      "Total number of tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "total_tokens = tokenizer.encode(text_data)\n",
    "print(f\"Total characters: {len(text_data)}\")\n",
    "print(f\"Total number of tokens: {len(total_tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Create custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a custom DataSet which extends PyTorch's `Dataset` to prepare an LLM training dataset, which\n",
    "- tokenizes the text dataset with a given tokenizer \n",
    "- chunks the text dataset into multiple chunks of max_length, with the specified stride\n",
    "- using a sliding window when chunking, so that\n",
    "  - input is a sequence of token ids\n",
    "  - target is one token slided right of the input token id sequence\n",
    "\n",
    "We do this by preprocessing logic in `__init__` method and then override the `__len__` method and `__getitem__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        # Tokenize the entire text\n",
    "        token_ids = tokenizer.encode(txt, allowed_special={\"<|endoftext|>\"})\n",
    "\n",
    "        # Use a sliding window to chunk the book into overlapping sequences of max_length\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            target_chunk = token_ids[i + 1: i + max_length + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use this custom dataset in PyTorch's `DataLoader`, which takes care of data batching, shuffling, parallel data loading, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "    # Create dataset\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "\n",
    "    # Create dataloader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With those prepared, let's split the dataset into training and validation at ratio 9:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's create the dataloaders for training and validation datasets. \n",
    "- For faster training, we change the model config's context_length from 1024 to 256\n",
    "- We set `drop_last=True` in the datalodaer so that if there are not enough samples left to form a full batch at the end of the dataset, we drop this smaller final batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length !! Let's use 256 context length for faster training\n",
    "    \"embedding_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"dropout_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check if the data is enough to cover at least context length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(total_tokens) * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if len(total_tokens) * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that data was loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that token size is in the expected ballpark (we droped the last smaller batch so it is smaller than the full dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4608\n",
      "Validation tokens: 512\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Calculate loss batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement two utils functions to calculate `cross-entropy` loss. \n",
    "\n",
    "One is for a given batch. We will use the model to generate logits for this input batch, then use PyTorch's cross entropy loss implementation `torch.nn.functional.cross_entropy`, passing in flattened batch `logits` and flattened batch `target_batch` IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can calculates loss for multiple batches across a dataloder. We calculate each batch's loss then get the average loss of all batches we're interested in the dataloder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches = None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float('nan')\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(MPS seems to get faster the second time round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU : --- 0.27613019943237305 seconds ---\n",
      "MPS : --- 0.00039196014404296875 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "TENSOR_A_CPU = torch.rand(5000, 5000)\n",
    "TENSOR_B_CPU = torch.rand(5000, 5000)\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "TENSOR_A_MPS = torch.rand(5000, 5000).to(device)\n",
    "TENSOR_B_MPS = torch.rand(5000, 5000).to(device)\n",
    "\n",
    "# Warm-up\n",
    "for _ in range(100):\n",
    "    torch.matmul(torch.rand(500,500).to(device), torch.rand(500,500).to(device))\n",
    "    \n",
    "start_time = time.time()\n",
    "torch.matmul(TENSOR_A_CPU, TENSOR_B_CPU)\n",
    "print(\"CPU : --- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "start_time = time.time()\n",
    "torch.matmul(TENSOR_A_MPS, TENSOR_B_MPS)\n",
    "print(\"MPS : --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's calculate the dataset's loss on an untrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt.gpt_model import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length !! Let's use 256 context length for faster training\n",
    "    \"embedding_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"dropout_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train loss: 11.0054654015435105\n",
      "Initial validation loss: 11.0061912536621094\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "with torch.no_grad(): # disable gradient tracking for efficiency as we're not yet training\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(f\"Initial train loss: {train_loss:.16f}\")\n",
    "print(f\"Initial validation loss: {val_loss:.16f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Train and eval scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple training script that will give us `train_losses`, `val_losses`, and `track_tokens_seen` which tracks all tokens the model has seen.\n",
    "\n",
    "In each epoch, we\n",
    "- set the model in training mode\n",
    "- go through each batch, wherein we\n",
    "  - reset the optimizers gradients from the previous iteration: `optimizer.zero_grad()`\n",
    "  - calculate loss of this batch (use the model to generate logits of the input_batch, then calculate cross entropy loss of the input_batch and target_batch)\n",
    "  - calculate gradient using back propagation of the loss (`loss.backword()`)\n",
    "  - update model weights using the optimizer with the gradients (`optimizer.step()`)\n",
    "  - track tokens seen\n",
    "  - every `eval_freq` steps, we print out the intermediate training results:\n",
    "    - set the model in eval() mode\n",
    "    - calculate loss across `eval_iter` batches\n",
    "    - print the number of tokens seen, the intermediate train and val loss\n",
    "    - use the model to do a text generation and print it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    # lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # set model to training mode\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()  # reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()  # calculate gradients\n",
    "            optimizer.step()  # update model weights\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # intermediate evaluation\n",
    "            if global_step % eval_freq == 0:\n",
    "                model.eval()  # set model to evaluation mode\n",
    "                with torch.no_grad():\n",
    "                    train_loss = calc_loss_loader(\n",
    "                        train_loader, model, device, eval_iter\n",
    "                    )\n",
    "                    val_loss = calc_loss_loader(val_loader, model, device, eval_iter)\n",
    "                    train_losses.append(train_loss)\n",
    "                    val_losses.append(val_loss)\n",
    "                    track_tokens_seen.append(tokens_seen)\n",
    "                    print(\n",
    "                        f\"Epoch: {epoch}, Global step: {global_step}, \"\n",
    "                        f\"Tokens seen: {tokens_seen}, Train loss: {train_loss:.4f}, \"\n",
    "                        f\"Validation loss: {val_loss:.4f}\"\n",
    "                    )\n",
    "                model.train()\n",
    "        # print a samplet text after each epoch\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every epoch we print a text generation to see if the model is getting better. \n",
    "\n",
    "The `generate_and_print_sample` utility function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.generate_tokens import generate_tokens_greedy\n",
    "import torch\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded_tensor = torch.tensor(tokenizer.encode(start_context)).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_tokens_greedy(\n",
    "            model=model,\n",
    "            input_idx_batch=encoded_tensor,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size,\n",
    "        )\n",
    "    decoded_text = tokenizer.decode(token_ids.squeeze(0).tolist())\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the LLM using the above training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Global step: 0, Tokens seen: 512, Train loss: 10.0420, Validation loss: 10.0227\n",
      "Epoch: 0, Global step: 5, Tokens seen: 3072, Train loss: 8.1697, Validation loss: 8.3290\n",
      "Every effort moves you,,,,, the,,,,,,, the,,,,,,,,,,,,,,,,,,,,,,,, the,,,,,,,,,,,\n",
      "Epoch: 1, Global step: 10, Tokens seen: 5632, Train loss: 6.7131, Validation loss: 7.0844\n",
      "Epoch: 1, Global step: 15, Tokens seen: 8192, Train loss: 6.1807, Validation loss: 6.6203\n",
      "Every effort moves you, and, and, the, and, and, and, the, and, and, and, and, and, and, and, the, and, and, and, and, and, and, and,, and, the,\n",
      "Epoch: 2, Global step: 20, Tokens seen: 10752, Train loss: 5.6658, Validation loss: 6.5348\n",
      "Epoch: 2, Global step: 25, Tokens seen: 13312, Train loss: 5.6759, Validation loss: 6.4869\n",
      "Every effort moves you .                                                 \n",
      "Epoch: 3, Global step: 30, Tokens seen: 15872, Train loss: 5.2342, Validation loss: 6.4239\n",
      "Epoch: 3, Global step: 35, Tokens seen: 18432, Train loss: 5.0158, Validation loss: 6.4387\n",
      "Every effort moves you.  \"  \"   \"I, and my, and, and I was, and I had. \"--I, and his, and the. I had, and the, and my, and the, and\n",
      "Epoch: 4, Global step: 40, Tokens seen: 20992, Train loss: 4.5761, Validation loss: 6.3260\n",
      "Every effort moves you.            \"I--I to my work, and my I had been to me, I was his a had been the a had the first, I had been--I had the first his\n",
      "Epoch: 5, Global step: 45, Tokens seen: 23552, Train loss: 4.3395, Validation loss: 6.2687\n",
      "Epoch: 5, Global step: 50, Tokens seen: 26112, Train loss: 3.6068, Validation loss: 6.1634\n",
      "Every effort moves you know that he had been the picture--I turned, and I feltI turned.                                 \n",
      "Epoch: 6, Global step: 55, Tokens seen: 28672, Train loss: 3.2385, Validation loss: 6.1704\n",
      "Epoch: 6, Global step: 60, Tokens seen: 31232, Train loss: 3.1312, Validation loss: 6.1857\n",
      "Every effort moves you know that, and a little of the Riv he was a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, I had dropped his painting, I had been the Riv, and I had\n",
      "Epoch: 7, Global step: 65, Tokens seen: 33792, Train loss: 2.4549, Validation loss: 6.1865\n",
      "Epoch: 7, Global step: 70, Tokens seen: 36352, Train loss: 2.1967, Validation loss: 6.1622\n",
      "Every effort moves you know,\" was one of the picture--I--I told Mrs.                                    \n",
      "Epoch: 8, Global step: 75, Tokens seen: 38912, Train loss: 1.7021, Validation loss: 6.2075\n",
      "Epoch: 8, Global step: 80, Tokens seen: 41472, Train loss: 1.2627, Validation loss: 6.2705\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisburn's an unusual degree to the display of the his glory, the donkey.  \"Oh, when Stroud laid in the first\n",
      "Epoch: 9, Global step: 85, Tokens seen: 44032, Train loss: 1.0119, Validation loss: 6.2917\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and Mrs.  \"I turned--had lent herself in an unusual degree to the display of his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Training took 2.56 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from gpt.gpt_model import GPTModel\n",
    "\n",
    "start_time = time.time()\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 256,  # Context length !! Let's use 256 context length for faster training\n",
    "    \"embedding_dim\": 768,  # Embedding dimension\n",
    "    \"n_heads\": 12,  # Number of attention heads\n",
    "    \"n_layers\": 12,  # Number of layers\n",
    "    \"dropout_rate\": 0.1,  # Dropout rate\n",
    "    \"qkv_bias\": False,  # Query-Key-Value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=\"Every effort moves you\",\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training took {execution_time_minutes:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Plot the training and validation losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Train Loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation Loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # force integer ticks on x-axis\n",
    "\n",
    "    # plot a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # create a dummy plot\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe overfitting as at the beginning both train and val losses are going down, but after a couple of epochs only the train loss keeps going down while the val loss plateaued. \n",
    "\n",
    "The overfitting is because we have a very small training set and we're iterating over it many times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Learning rate warmup and cosine decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradually increase learning rate from a very low value (`initial_lr`, e.g. 0.0001) to a maximum value (`peak_lr`, e.g. 0.01). \n",
    "\n",
    "Benefit: stablize the training at the initial stage. Model training starts with samll weight updates, which can decrease the risk of large destablizing updates.\n",
    "\n",
    "Typically, the number of warmup steps is between 0.1% to 10% of the total number of global training steps. We calculate each step's learning rate increment evenly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total steps: 90, warmup steps: 18\n"
     ]
    }
   ],
   "source": [
    "initial_lr = 0.0001\n",
    "peak_lr = 0.01\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "warmup_steps = int(0.2 * total_steps) # 20% of total steps warm up\n",
    "print(f\"total steps: {total_steps}, warmup steps: {warmup_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning rate cosine decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After warming up steps, decrease the learning rate across training epochs to near zero. In cosine decay, the learning rate decrease follows a half cosine cycle curve to near zero. \n",
    "\n",
    "Benefit: \n",
    "- stablize the training at its later stages. It's designed to slow down the pace of weight update and reduce the risk of overshooting minima as the training progresses. \n",
    "- Cosine decay is often preferred over linear decay for its smoother transition in learing rate adjustments. But linear decay is also used in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "initial_lr = 0.0001\n",
    "\n",
    "# for lr warmup\n",
    "peak_lr = 0.01\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "warmup_steps = int(0.2 * total_steps) # 20% of total steps warm up\n",
    "lr_increment = (peak_lr - initial_lr) / warmup_steps\n",
    "# for lr cosine decay\n",
    "min_lr = 0.1 * initial_lr\n",
    "\n",
    "global_step = -1\n",
    "track_lrs = []\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.1)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for input_batch, target_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        global_step += 1\n",
    "\n",
    "        # linear warmup\n",
    "        if global_step < warmup_steps:\n",
    "            lr = initial_lr + global_step * lr_increment\n",
    "        # cosine annealing after warmup\n",
    "        else:\n",
    "            progress = (global_step - warmup_steps) / (total_steps - warmup_steps)\n",
    "            lr = min_lr + (peak_lr - min_lr) * 0.5 * (1 + math.cos(math.pi * progress))\n",
    "        \n",
    "        # apply the calculated learningg rate to the optimizer\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "        track_lrs.append(optimizer.param_groups[0][\"lr\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
